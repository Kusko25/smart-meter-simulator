{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_path = Path(r\"Datasets\\Smart meters in London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_acorn_csv = base_path / 'data' / 'informations_households.csv'\n",
    "assert path_acorn_csv.exists(), f\"File not found: {path_acorn_csv}\"\n",
    "\n",
    "lookup_dict = {}\n",
    "lookup_df = pd.read_csv(path_acorn_csv)\n",
    "\n",
    "# Drop all rows with Acorn not in [ACORN-A, ... , ACORN-V]\n",
    "lookup_df = lookup_df[lookup_df['Acorn'].str.match(r'ACORN-[A-Z]')]\n",
    "lookup_df = lookup_df[['LCLid', 'Acorn', 'Acorn_grouped']]\n",
    "lookup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = pd.read_csv(base_path / 'data/processed.csv')\n",
    "value_columns = [f'{i:02}:00' for i in range(0,24)]\n",
    "\n",
    "# Add columns for the Acorn and Acorn_grouped\n",
    "day_df['Acorn'] = day_df['LCLid'].map(lookup_df.set_index('LCLid')['Acorn'])\n",
    "day_df['Acorn_grouped'] = day_df['LCLid'].map(lookup_df.set_index('LCLid')['Acorn_grouped'])\n",
    "\n",
    "# Drop NaN values\n",
    "day_df = day_df.dropna(subset=['Acorn'])\n",
    "\n",
    "# Pick date with most data\n",
    "date = day_df['date'].value_counts().idxmax()\n",
    "day_df = day_df[day_df['date'] == date]\n",
    "print(date, day_df.shape)\n",
    "\n",
    "print(day_df.value_counts('Acorn')/day_df['Acorn'].count())\n",
    "print(day_df.shape)\n",
    "\n",
    "\n",
    "# Split into training and test set. Preserve Acorn distribution\n",
    "train_df, test_df = train_test_split(day_df, test_size=0.4, stratify=day_df['Acorn'])\n",
    "print(train_df.value_counts('Acorn')/train_df['Acorn'].count())\n",
    "print(train_df.shape)\n",
    "print(test_df.value_counts('Acorn')/test_df['Acorn'].count())\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = train_df.copy()\n",
    "temp_df['min_hour'] = temp_df[value_columns].min(axis=1)\n",
    "temp_df['max_hour'] = temp_df[value_columns].max(axis=1)\n",
    "temp_df['sum_day'] = temp_df[value_columns].sum(axis=1)\n",
    "\n",
    "# Plot the distribution of max_hour grouped by Acorn\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.boxplot(data=temp_df, x='max_hour', hue='Acorn', ax=ax[0])\n",
    "sns.boxplot(data=temp_df, x='sum_day', hue='Acorn', ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m0   m1 (New Previous)    m2 Previous          m3 Current          m4 Verifier      m5 (New Current)           m6 (New Verifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get boxplot data\n",
    "box_data = temp_df.groupby('Acorn')['sum_day'].describe()\n",
    "# IQR and cutoff\n",
    "box_data['IQR'] = box_data['75%'] - box_data['25%']\n",
    "box_data['cutoff'] = box_data['75%'] + 1.5 * box_data['IQR']\n",
    "box_data.to_csv(base_path / 'data' / 'boxplot_data.csv')\n",
    "box_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(base_path / 'data' / 'sm_data_manipultion_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cutoff from boxplot data for ACORN-A\n",
    "cutoff = box_data.loc['ACORN-C', 'cutoff']\n",
    "int(cutoff + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = pd.read_csv(base_path / 'data/processed.csv')\n",
    "value_columns = [f'{i:02}:00' for i in range(0,24)]\n",
    "threshold_df = pd.DataFrame(columns=['LCLid', 'Q0', 'Q1', 'Q2', 'Q3', 'Q4', 'mean'])\n",
    "\n",
    "day_df['day_sum'] = day_df[value_columns].sum(axis=1)\n",
    "for sm in day_df['LCLid'].unique():\n",
    "    sm_data = day_df[day_df['LCLid'] == sm]\n",
    "    sm_data = sm_data['day_sum'].sort_values()\n",
    "    q0 = sm_data.iloc[0]\n",
    "    q1 = sm_data.quantile(0.25)\n",
    "    q2 = sm_data.quantile(0.5)\n",
    "    q3 = sm_data.quantile(0.75)\n",
    "    q4 = sm_data.iloc[-1]\n",
    "    mean = sm_data.mean()\n",
    "    threshold_df.loc[len(threshold_df)] = [sm, q0, q1, q2, q3, q4, mean]\n",
    "display(threshold_df.head())\n",
    "display(threshold_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = threshold_df.copy()\n",
    "temp_df['group'] = pd.qcut(temp_df['mean'], 30)\n",
    "# Mean of the groups\n",
    "temp_df['threshold_soft'] = temp_df['group'].apply(lambda x: x.right * 3).astype(int)\n",
    "temp_df['threshold_hard'] = temp_df['group'].apply(lambda x: x.right * 2).astype(int)\n",
    "temp_df.to_csv(base_path / 'data' / 'threshold_data.csv')\n",
    "temp_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
