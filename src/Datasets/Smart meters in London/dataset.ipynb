{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "base_path = Path(r\"Datasets\\Smart meters in London\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acorn Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_acorn_csv = base_path / 'data' / 'informations_households.csv'\n",
    "assert path_acorn_csv.exists(), f\"File not found: {path_acorn_csv}\"\n",
    "\n",
    "lookup_dict = {}\n",
    "lookup_df = pd.read_csv(path_acorn_csv)\n",
    "\n",
    "# Drop all rows with Acorn not in [ACORN-A, ... , ACORN-V]\n",
    "lookup_df = lookup_df[lookup_df['Acorn'].str.match(r'ACORN-[A-Z]')]\n",
    "lookup_df = lookup_df[['LCLid', 'Acorn', 'Acorn_grouped']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we want:\n",
    "# A list of shape LCLid, date, 00:00, 00:30, 01:00, 01:30, ..., 23:30\n",
    "# Where the values are the energy consumption for that half hour\n",
    "\n",
    "# What we have:\n",
    "# A list of shape LCLid, timestamp, energy consumption\n",
    "# Where the timestamp is in the format YYYY-MM-DD HH:MM:SS.0000000\n",
    "\n",
    "data = {}\n",
    "\n",
    "# LCLid,tstp,energy(kWh/hh)\n",
    "# MAC000026,2011-12-07 11:00:00.0000000, 0.611 \n",
    "for i in range(0,20):\n",
    "    # Try to read all to see if there are any errors\n",
    "    print(f'block_{i}.csv')\n",
    "    df = pd.read_csv(\n",
    "        f'data/block_{i}.csv', \n",
    "        dtype={'LCLid': 'str', 'tstp': 'str', 'energy(kWh/hh)': 'float'}, \n",
    "        on_bad_lines='warn',\n",
    "        na_values=['Null']\n",
    "    )\n",
    "    df['LCLid'] = df['LCLid'].astype('str')\n",
    "    df['tstp'] = pd.to_datetime(df['tstp'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df['date'] = df['tstp'].dt.date\n",
    "    df['time'] = df['tstp'].dt.time\n",
    "    df.drop(columns=['tstp'], inplace=True)\n",
    "    \n",
    "    df['energy'] = df['energy(kWh/hh)'].astype('float')\n",
    "    df.drop(columns=['energy(kWh/hh)'], inplace=True)\n",
    "    \n",
    "    df['energy'] = df['energy'] * 1000 # Convert to Wh\n",
    "    df['energy'] = df['energy'].astype('int')\n",
    "    \n",
    "    for id, date, time, energy in df.values:\n",
    "        if id not in data:\n",
    "            data[id] = {}\n",
    "        if date not in data[id]:\n",
    "            data[id][date] = {}\n",
    "        data[id][date][time] = energy\n",
    "\n",
    "rows = []\n",
    "for id, dates in data.items():\n",
    "    for date, times in dates.items():\n",
    "        readings = [list() for _ in range(24)]\n",
    "        for time, energy in times.items():\n",
    "            hour = time.hour\n",
    "            readings[hour].append(energy)\n",
    "        if any(len(r) == 0 for r in readings):\n",
    "            print(f'Error in {id} {date}', readings)\n",
    "            continue\n",
    "        for i in range(24):\n",
    "            if len(readings[i]) == 1:\n",
    "                readings[i] = readings[i] + readings[i]\n",
    "        row = [id, date] + [sum(r) for r in readings]\n",
    "        rows.append(row)\n",
    "print(f'Writing {len(rows)} rows')\n",
    "headers=['LCLid', 'date'] + [f'{i:02}:00' for i in range(0,24)]\n",
    "out_df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Keep at most 5 entries per LCLid\n",
    "# out_df = out_df.groupby('LCLid').sample(5)\n",
    "\n",
    "out_df.shape\n",
    "out_df.to_csv('data/processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how many entries we have for each date\n",
    "step = out_df.groupby('date').size()\n",
    "# Filter out dates with less than 100 entries\n",
    "step = step[step > 100]\n",
    "# Pick a random date from that list\n",
    "date = step.sample(1).index[0]\n",
    "# Filter out all entries that are not from that date\n",
    "out_df[out_df['date'] == date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = pd.read_csv('data/processed.csv')\n",
    "value_columns = [f'{i:02}:00' for i in range(0,24)]\n",
    "# Add column for max min sum and mean\n",
    "day_df['max'] = day_df[value_columns].max(axis=1)\n",
    "day_df['min'] = day_df[value_columns].min(axis=1)\n",
    "day_df['sum'] = day_df[value_columns].sum(axis=1)\n",
    "day_df['mean'] = day_df[value_columns].mean(axis=1)\n",
    "# Group by LCLid merge the columns\n",
    "day_df = day_df.groupby('LCLid').agg({\n",
    "    'max': 'max',\n",
    "    'min': 'min',\n",
    "    'sum': 'mean',\n",
    "    'mean': 'mean'\n",
    "})\n",
    "\n",
    "# Merge with lookup_df on LCLid\n",
    "day_df = day_df.merge(lookup_df, on='LCLid')\n",
    "day_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(day_df, hue='Acorn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
